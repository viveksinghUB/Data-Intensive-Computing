# Data-Intensive-Computing
Data Intensive Computing projects using MapReduce, Spark, Hadoop, Tableau<br><br>

It comprises of DIC projects implemented in Jupyter notebook or R Studio in R language.<br><br>
<br><br>
H1B analytics Tableau Dashboard

<br><br>
Tesserae project_n gram word count

<br><br>
Large scale text processing with Hadoop Map Reduce

Data Clients and Information Servers <br> 
GOALS:<br> <br> 
 1. Install a work environment for carrying out various activities of the data science process.
<br>  2. Understand and implement Application Programming Interface (API) based programmatic data collection from popular (/public) data sources (Data clients).
<br>  3. Process the data collected for extracting basic information.
<br>  4. Serve the information extracted through simple applications and visualization (Information servers).

<br> Data Cleaning and Munging<br> 
GOALS:<br> <br> 

<br> Convert data in various format into a form that is convenient for in-memory operations. Transform from external storage formats such as xml, sqllite into a common external format, comma separated value (.csv) convenient for exploratory data analysis using R. This allows for easy reading of data into the memory as data frames.
<br> Extract (data munging) useful data from raw data collected by real survey instruments. You will use the actual survey document in interpreting the survey results.
<br> Repurpose data from a popular domain (such as sports) for consumption by different genre of applications.
<br> Transform data using operations such as grouping, categorization and binning to stage them for in-memory analysis. (R is optimized to work well with in-memory data.)
<br> Document data cleaning steps using Markdown, a text-based HTML authoring format. This is an essential step in “reproducible research” and is offered within Jupyter platform.
<br> Learn and understand the scientific data collection process, surveys, and nature of raw data and the need and motivation for cleaning and munging the data.

<br> Algorithms and Models for Data Analysis, Learning and Prediction.
<br> GOALS:<br> <br> 

<br> <br> Decide on the algorithms that will be used in solving the problem based on the data characteristics and the attributes of the problems.
<br> Learn to apply algorithms: linear regression, K-NN and K-means, which algorithm to use and why and when.
<br> Make valid and reasonable assumptions about the variables (features) of a problem, goodness of a model fit, metrics for evaluation of errors, outliers, scaling, and choosing appropriate data ranges for the computation.
<br> Choose the parameters for prediction based on experimentation (repeated trials) and acceptable values of error rates. Document the experimentation process and the rationale.
<br> Plot the outcomes for easy visualization of data analysis.
<br> Interpret the results to enable decision making.

